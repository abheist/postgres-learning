- Intervals (done)
```sql
-- think of interval as a duration, this makes certain queries very simple.

select 'unit quantity .. ..'::interval;

select '1 year'::interval; -- 1 year
select '1 year 2 month 3 days 4 hours 5 minutes 6 seconds'::interval;
-- 1 year 2 mons 3 days 04:05:06

-- so we can also do:
select '1 year 2 month 3 days 04:05:06'::interval;
-- 1 year 2 mons 3 days 04:05:06

show intervalstyle; -- postgres
set intervalstyle = 'iso_8601'; -- OK
select '1 year 2 month 3 days 04:05:06'::interval;
-- P1Y2M3DT4H5M6S
-- it is P 1Y 2M 3D T 4H 5M 6S

select interval '2' year; -- 2 years
select interval '1-6' year to month; -- 1 year 6 mons
select interval '6000' seconds; -- 01:40:00
```
- Serial types (done)
```sql
-- after posrgres 10, serial is not recommended way to create primary key, there is more simpler way to create one now.

-- serial under the hood uses sequences

create table serial_example (
	id serial
);
-- â†“ under the hood it creates the following

create sequence serial_example_id_seq as integer;
create table serial_example (
	id integer not null default nextval('serial_example_id_seq')
);
alter sequence serial_example_id_seq owned by serial_example.id; -- this is added once the table is created, now if you drop the table, or drop the column, the sequence will also be destroyed.
-- nextval() function is ??

-- So one keyword `serial` is expanding to whole new statement. 

-- In any case, if you have to use Serial, then use BIGSERIAL in that case. as BIGSERIAL uses biginteger and since we are using serial for primary-key or auto-increment key, then we do not want the keys to run out of space.

create table serial_example (
	id bigserial primary key
);

-- now user sequence as order number generator

create table orders (
	id bigint generated always as identity primary key,
	order_number serial,
	customer_name varchar(100),
	order_date date,
	total_amount numeric(10, 2)
)

insert into orders
	(customer_name, order_date, total_amount)
values
	('John Doe', '2024-09-24', 150.00),
	('Jane Smith', '2024-09-24', 200.50),
	('Bob Johnson', '2024-09-25', 75.25);
-- here we are not passing id or order_number, they both will generate via postgres

select * from orders; -- this will have new id and order_number auto-generated in sequence: 1,2,3...

-- Note: here we have to do select again after insert. But postgres provides functionality to return the result in same query vai RETURNING keyword.
insert into orders
	(customer_name, order_date, total_amount)
values
	('John Doe', '2024-09-24', 150.00)
returning id, order_numer; -- this will only show two columns: id and order_number. or you can have entire row via wild-card *


```
- Sequences (done)
```sql
create sequence seq 
	as bigint
	increment 1
	start 1
	minvalue 1
	maxvalue 93242374241231234234;

select nextval('seq'); -- if you run this query multiple times, it will keep incrementing. This will provide the next value from DB even if the session is running on multiple clients. 

select currval('seq'); -- this will provide the current value of the sequence. mainly the last value which nextval provided in the same session. If you have another session where you ran multiple times nextval and session reaches to 100. But the current session currval will give you 37 if the last value of current session was 37.

select setval('seq', 1); -- do not use this, otherwise it might create duplicates, use it as per use-case.
```
- Identify (done)
```sql
create table id_example (
	id bigint generated always as identity primary key,
	name text
);

insert into id_example (name) values ('John'); -- if we run this multiple times, it will automatically create id.

select * from id_example; -- to show the newly generated row and ids

-- but if we try to manually insert id, it will throw an error.
insert into id_example (id, name) values (12, 'John'); -- Error

-- but this behaviour can be overridden by:
insert into id_example (id, name) overriding system value values (16, 'Aaron'); -- this will throw error if the key already exists, otherwise it will create new row with the provided key, but the issue will be that key was not auto-incremented.

-- once we used manual insert with ID via overriding the system value, then, the new value is messed up the sequence, because at some point in future, we'll reach the value which is inserted manually and that will throw an error, to fix this, we have to run the following:

-- first get the sequence of the identity by following
-- identity under the hood also uses sequences, but it is wrapped up nicely under the hood
select pg_get_serial_sequence('id_example', 'id') -- pass table_name and column_name

-- then set the value of sequence by getting the max id from our table
select setval('public.id_example_id_seq', (select max(id) from id_example));

-- There is other option for manual entry to table id
drop table id_example;

-- to use "generated by default"
create table id_example (
	id bigint generated by default as identity primary key,
	name text
);

-- now we can manually insert the id
insert into id_example (name) values ('John'); -- if we run this multiple times, it will automatically create id.

-- but if we try to manually insert id, it will let us insert.
insert into id_example (id, name) values (12, 'John');
-- 
```
- Network and mac addresses (done)
```sql
create table inet_example (
	id bigint generated always as identity primary key,
	ip_address inet
);

insert into inet_examples (ip_address)
values
	('192.168.1.10/24'), -- Host address with subnet mask
	('10.0.0.1'), -- Host address without subnet
	('::1/128'), -- IPv6 loopback address
	('2001:db8::/32'), -- IPv6 network
	('2001:db8:85a3:8d3:1319:8a2e:370:7348'); -- IPv6 host address

select * from inet_example;

select pg_column_size('2001:db8:85a3:8d3:1319:8a2e:370:7348'::text) as a,
	   pg_column_size('2001:db8:85a3:8d3:1319:8a2e:370:7348'::inet) as b;

--|  text    |  inet   |
--|----------|---------|
--|   40     |   22    |

-- here there is some other datastrucutre which is implemented behind the schene for inet. This is not an string.

select ip_address,
	host(ip_address) as host_only, -- Extracts the host part
	masklen(ip_address) as mask_length, -- Extracts the prefix lenth
	network(ip_address) as network_only, -- Extracts the network portion
	abbrev(ip_address) as abbreviated_ip -- Abbreviates IPv6 address
from inet_examples;
```
<table>
    <tr>
        <th>ip_address</th>
        <th>host_only</th>
        <th>mask_length</th>
        <th>network_only</th>
        <th>abbreviated_ip</th>
    </tr>
    <tr>
        <td>192.168.1.10/24</td>
        <td>192.168.1.10</td>
        <td>24</td>
        <td>192.168.1.0/24</td>
        <td>192.168.1.10/24</td>
    </tr>
    <tr>
        <td>10.0.0.1</td>
        <td>10.0.0.1</td>
        <td>32</td>
        <td>10.0.0.1/32</td>
        <td>10.0.0.1</td>
    </tr>
    <tr>
        <td>::1</td>
        <td>::1</td>
        <td>128</td>
        <td>::1/128</td>
        <td>::1</td>
    </tr>
    <tr>
        <td>2001:db8::/32</td>
        <td>2001:db8::</td>
        <td>32</td>
        <td>2001:db8::/32</td>
        <td>2001:db8::/32</td>
    </tr>
    <tr>
        <td>2001:db8:85a3:8d3:1319:8a2e:370:7348</td>
        <td>2001:db8:85a3:8d3:1319:8a2e:370:7348</td>
        <td>128</td>
        <td>2001:db8:85a3:8d3:1319:8a2e:370:7348/128</td>
        <td>2001:db8:85a3:8d3:1319:8a2e:370:7348</td>
    </tr>
</table>
```sql
-- for mac-address, we can use macaddr data-type
select '08:00:2b:01:02:03'::macaddr; -- 6 byte version
select '08:00:2b:01:02:03'::macaddr8; -- 8 byte version
```
---
- JSON (done)
```sql
-- there are two different types to store json on postgres
-- json
-- jsonb

select '1'::json; -- 1
select pg_typeof('1'::json); -- json

-- use jsonb not json

select '1'::json -- 1
	   '1'::jsonb; -- 1

select pg_column_size('1'::json) as json, -- 5
	   pg_column_size('1'::jsonb) as jsonb; -- 20
-- either json has smaller size, but jsonb is stored as binary, and json is stored as text. on jsonb, postgres provides few more utilities to work with. and as json size starts increasing, jsonb will be less in size.

select
	'{"a" : "Hello world"}'::json,
	'{"a" : "Hello world"}'::jsonb;

--| json                  | jsonb                |
--|-----------------------|----------------------|
--| {"a" : "Hello world"} | {"a": "Hello world"} |

-- but what if, I change the value of json with extra spaces
select
	'{"a" :      "Hello world"}'::json,
	'{"a" :      "Hello world"}'::jsonb;

--| json                       | jsonb                |
--|----------------------------|----------------------|
--| {"a" :      "Hello world"} | {"a": "Hello world"} |

-- here you'll that json kept those extra space while jsonb fixed that removed those unwanted extraspace from the json.
-- jsonb has more rules as well, which are not considered by json.
-- it parsed the json and validate that it should be a valid json, like it will not allow duplicate keys and overwrite the initial key value with the one which was defined later in json..

-- You can directly extract key's value from the query.
select '
{
	"string": "Hello World",
	"number": 42,
	"boolean": true,
	"null": null,
	"array": [
		1,2,3
	],
	"object": {
		"key": "value"
	}
}
'::jsonb->'string'; -- "Hello World" // here 'string' is key
-- if we want the unquoted text we can use '->>'
-- we can also get deeply nested keys via
select '{...}'::json->'object'->'key'
```
- Arrays (done)
```sql
create table array_example (
	id bigint generated always as identity primary key,
	int_array integer array, -- we can define array by [] or 'array'
	text_array text[],
	bool_array boolean[],
	nested_array integer[][]
)

insert into array_example
	(int_array, text_array, bool_array)
values
	(
		array [1,2,3,4],
		array ['marigold', 'daisy', 'poppy', 'sunflower'],
		array [true, false, true, false]
	);
-- or we can use the following format, which uses {}

insert into array_example
	(nested_array)
values
	('{{1,2,3}, {4,5,6}, {7,8,9}}');

select
	id, text_array -- 1, {marigold, daisy, poppy, sunflower}
from array_example;

select
	id, text_array[1] -- 1, marigold
from array_example; 
-- here indexing is 1 based, not zero based, so if you put zero, you'll get NULL
select
	id, text_array[0] -- 1, NULL
from array_example; 

-- we can do slices
select
	id, text_array[1:3] -- 1, {'marigold', 'daisy', 'poppy'}
from array_example;

-- all these will work, just like python [2:], [:3]

-- you can also do where on array contains
select
	id, text_array
from array_example
where
	text_array @> array['poppy']; -- this will show the row whose text_array contains poppy

-- @> is array contains sign, same thing will work with {}

select
	id, text_array
from array_example
where
	text_array @> '{poppy}'; -- this will show the row which contains poppy


select id, unnest(text_array)
from array_example; -- this will divide the array into its separate rows.

--| id | unnest    |
--|----|-----------|
--|  1 | marigold  |
--|  1 | daisy     |
--|  1 | poppy     |
--|  1 | sunflower |

-- you can do queries likeL
with flowers as (
	select id, unnest(text_array)
	from array_example
); 

select * from flowers;

-- and with where clause

with flowers as (
	select id, unnest(text_array) as flower
	from array_example
); 

select * from flowers where flower = 'poppy';
```
- Generated columns (done)
```sql
-- there are two types of generated columns, virtual and stored.
-- postgres only supports stored generated columns

create table people (
	height_cm numeric,
	height_in numeric generated always as (height_cm / 2.54) stored
);

insert into people (height_cm) values (100), (200);

select * from people;
--| height_cm | height_in           |
--|-----------|---------------------|
--|       200 | 78.7401574803149606 |
--|       210 | 82.6771653543307087 |

--If you try to enter data in generated column, it will throw an error

create table users (
	email text,
	email_domain text generated always as (split_part(email, '@', 2)) stored 
); -- remember it is 1 indexed

insert into users (email) values ('abhishek@gmail.com');
insert into users (email) values ('abhishek@gmail.com');

select * from users;
--| email              | email_domain |
--|--------------------|--------------|
--| abhishek@gmail.com | gmail.com    |
--| abhishek@gmail.com | gmail.com    |

-- restrictions to generated columns
-- you have to reference the current row, you cannot reference other rows or other tables, subqueries, anything like that.
-- you can only use pure functions, given an input, it must always produce the same output
-- you cannot reference other generated columns.
```
- Text search types (done)
```sql
select to_tsvector('the quick brown fox jumps over the lazy dog');
--| to_tsvector                                           |
--|-------------------------------------------------------|
--| 'brown':3 'dog':9 'fox':4 'jump':5 'lazi':8 'quick':2 |

select pg_typeof(to_tsvector('the quick brown fox jumps over the lazy dog'));
--| pg_typeof |
--|-----------|
--| tsvector  |

--AÂ `tsvector`Â value is a sorted list of distinctÂ _lexemes_, which are words that have beenÂ _normalized_Â to merge different variants of the same word. Sorting and duplicate-elimination are done automatically during input.

-- First we can take and text and convert into tsvector with the help of function to_tsvector and then that can be used to search a text with the help of to_query function.

select to_tsvector('the quick brown fox jumps over the lazy dog') @@ to_tsquery('lazy');
--| ?column? |
--|----------|
--| TRUE     |

-- the order of the query does not matter
select to_tsquery('lazy') @@ to_tsvector('the quick brown fox jumps over the lazy dog');

select to_tsvector('english', 'yes');
--| to_tsvector |
--|-------------|
--| 'yes':1     |

select to_tsvector('french', 'oui');
--| to_tsvector |
--|-------------|
--| 'oui':1     |

create table ts_example (
	id bigint generated always as identity primary key,
	content text, -- the raw text content
	search_vector_en TSVECTOR generated always as (to_tsvector(content)) stored
); -- Error: generation expression is not immuatable

create table ts_example (
	id bigint generated always as identity primary key,
	content text, -- the raw text content
	search_vector_en TSVECTOR generated always as (to_tsvector('english', content)) stored
); -- OK 

insert into ts_example (content)
values
	('the quick brown fox jumps over the lazy dog');

select * from ts_example;
--| id | content         | search_vector_en    |
--|----|-----------------|---------------------|
--|  1 | the quick brown | 'brown':3 'dog':9   |
--|    | fox jumps over  | 'fox':4 'jump':5    |
--|    | the lazy dog    | 'lazi':8 'quick':2  |
--|----|-----------------|---------------------|

insert into ts_example (content)
values
	('the quick brown fox jumps over the cat');

-- now if we do the query
select * from ts_example where search_vector_en @@ to_tsquery('lazy');
-- we will get only first row with lazy
```
- Bit string (done)
```sql
select B'0001', '0001'::BIT(4)
--| ?column? | bit  |
--|----------|------|
--| 0001     | 0001 |

-- this can be really usefull to store true false value. It is hard to reason about to save boolean in bit string, but what if there are 10 or more support 30 columns which just store true/false. In that case bit strings are really helpful.

-- You can perform boolean bit operations on bit string like AND, OR, XOR, etc
```
- Ranges (done)
```sql
-- Range is not type in itself, it is kinda meta type, where each range has subtype which can be integer, numeric, date, timestamp, etc.
-- ranges have lower and upper bound, inclusive and exclusive, and we query that these number falls under that defined range.

select '[1,5]'::int4range;

--| int4range |
--|-----------|
--| [1,6)     |

select '[1,5]'::numrange;

--| numrange |
--|----------|
--| [1,5]    |

-- There are two separate styles for range.
-- - ')' - Exclusive
-- - ']' - Inclusive
--  so, when we have [1, 6): the values we have are 1,2,3,4,5
-- and when we have [1,5]: the values we have are 1,2,3,4,5
-- But why the numrange remain incluse and int gave us exclusive ?
-- Because, numrange is continuous, means, it can have multiple subparts. like our max-range is 5, then 4.999 is valid. But that is not with INT.

-- we can also use constructor functions
select numrange(1, 5); -- [1,5)
select int4range(1, 5); -- [1,5)
-- these have 3rd parameter for inclusion or exclusion
select numrange(1, 5, '[]'); -- [1,5]
select int4range(1, 5, '[]'); -- [1,6)

create table range_example (
	id bigint generated always as identity primary key,
	int_range int4range, -- range for integer
	num_range numrange,  -- range for numeric
	date_range daterange,-- range for dates
	ts_range tsrange	 -- range for timestamps
	ts_range tstzrange	 -- range for timestamps with timezone
);

-- you can use the `@>` operator to check if a range contains a value
select * from range_example where int_range @> 5;

-- to find a range that overlaps with another range, you can use the `&&` operator
select * from range_example where int_range && '[11, 20)';

-- for intersection
select int4range(10, 20, '[]') * int4range(15, 25);

-- few more helpful functions
-- upper()
-- upper_inc()
-- lower()
-- lower_inc()

select '{[3,7), [8,9)}'::int4multirange;

--| int4multirange |
--|----------------|
--| {[3,7),[8,9)}  |

select '{[3,7), [8,9)}'::int4multirange @> 4; -- t
select '{[3,7), [8,9)}'::int4multirange @> 7; -- f
select '{[3,7), [8,9)}'::int4multirange @> 8; -- t
select '{[3,7), [8,9)}'::int4multirange @> 9; -- f


```
- Composite types (done)
```sql
-- most of the times you won't use this, but sometime, this is very helpful, like address

create type address as (
	number text,
	street text,
	city text,
	state text,
	postal text
);

select row('123', 'Main st', 'Sometown', 'ST', '12345')::address;
--| row                               |
--|-----------------------------------|
--| (123,"Main st",Sometown,ST,12345) |

select pg_typeof(row('123', 'Main st', 'Sometown', 'ST', '12345')::address);
-- address

create table addresses (
	id bigint generated always as identity primary key,
	addr address
);

insert into addresses
	(addr)
values
	(('123', 'Main st', 'Sometown', 'ST', '12345'));

select * from addresses;
--| id | addr                              |
--|----|-----------------------------------|
--|  1 | (123,"Main st",Sometown,ST,12345) |

-- but what if now you just want number out of addr column
select id, addr.number from addresses; -- throws ERROR

select id, (addr).number from addresses; -- for composite type, you have to wrap it with () and then query upon nested type.

-- Note: you cannot add constraints on nestted types;
```
- Nulls (done)
```sql
-- NULL are unknown values

-- Not null check
create table products (
	id bigint generated always as identity primary key,
	name text not null,
	price numeric not null check(price > 0)
);

-- NULL = NULL -- NULL
```
- Unique constraints (done)
```sql
create table products (
	-- here primary key means (not null, unique )
	id bigint generated always as identity primary key,
	-- for text, we can make it 'unique', but in this case, multiple rows
	-- can have NULL value, that this unique will not check. To constraint
	-- that, add 'not null'. Other option is to add 'nulls not distinct',
	-- this will allow only one value with null
	product_number text unique,
	name text not null,
	price numeric not null check(price > 0)
);

drop table products;

create table products (
	id bigint generated always as identity primary key,
	brand text not null,
	product_number text not null,
	name text not null,
	price numeric not null check(price > 0)

	-- with unique we can add composite constraints
	unique(brand, product_number)
);
```
- Exclusion constraints (done)
```sql
-- This is same as unique constraint but little bit more power and flexibity, but you't might not use them more often.

create table reservations (
	id bigint generated always as identity primary key,
	room_id integer,
	reservation_period tsrange,
	exclude using gist (reservation_period with &&)
);
-- this has a problem, where it is not considering room. So this wont allow to create reservation for other rooms.

drop table reservations;

create table reservations (
	id bigint generated always as identity primary key,
	room_id integer,
	reservation_period tsrange,
	exclude using gist (
		room_id with =,
		reservation_period with &&
	) -- we can use 'WHERE' conditions as well in exclusion constraints.
);
-- But to support equality operator on room_id, you have install the following extension
create extension if not exists btree_gist;
```
- Foreign key constraints (done)
```sql
-- here we are defining a table, and putting a constraint that it must a have a reference to other table, otherwise it will throw error.

create table states (
	id bigint generated always as identity primary key,
	name text
);

create table cities (
	id bigint generated always as identity primary key,
	state_id bigint references states(id),
	name text
);

insert into states (name) values ('Texas');
select * from states;
--| id | name  |
--|----|-------|
--|  1 | Texas |

insert into cities (state_id, name)
values
	(2, 'Dallas'); -- Error as 2 does not exist currently

insert into cities (state_id, name)
values
	(1, 'Dallas'); -- OK

select * from cities
--| id | state_id | name   |
--|----|----------|--------|
--|  2 |       1 â†’| Dallas | here 'â†’' sign is for foreign key

drop table cities;
-- to make it a table level constraint
create table cities (
	id bigint generated always as identity primary key,
	state_id bigint,
	name text,
	foreign key (state_id) references states(id)

	-- for composite foreign key, you can add both
	foreign key (a,b) references states(a,b)
-- this must be unique in foreign table as well, otherwise it will be chaos, as it go to foreign table and see there are multiple rows for the defined unique ref.
);

-- by default, you cannot delete a parent row without first deleting the child row. But you can change that by defining cascade.
create table cities (
	id bigint generated always as identity primary key,
	state_id bigint,
	name text,
	foreign key (state_id) references states(id) on delete cascade
); -- cascade are better if you understand you table maps and affects. But it can be chaotic, if you add it without knowing the after-affects.
```
