- Introduction to Schema (done)
	- In Postgres, we have `schema` and under `schema`, we have `tables`. this is not same as MySQL, where we have tables directly under database.
	- Please do not confuse with the schema of table, that is totally different and means: what is the structure of the table, what are datatypes, what are columns, etc.
	- By default every Postgres Database start by public schema.
	- Guidelines:
		- Small
		- Simple
		- Representative of data
		- Choose the data-type wisely, which should actually represent the data. Do the right way.

| MySQL                                     | Postgres                                                                                  |
| ----------------------------------------- | ----------------------------------------------------------------------------------------- |
| mysql_db<br>- table<br>- table<br>- table | postgres_db<br>- schema<br>   - table<br>   - table<br>   - table<br>- schema<br>- schema |

- Integers (done)
	- `drop table if exists smallint_example`
	- `create table smallint_example (person_name TEXT, age smallint)`
	- `smallint`/ `int2`: -32768 to 32767
	- `integer` / `int4`: -2,147,483,648  to 2,147,483,647
		- This covers most of our needs.
		- Give our day much room to grow, specially for primary key
	- `bigint`/`int8`: -9,223,372,036,854,774,808 to -9,223,372,036,854,774,807
	- Postgres does not have the concept of unsigned integers
- Numeric / Decimal (done)
	- They support fraction of numbers, they are accurate, but they are slow compared to int.
	- `create table numeric_example (description text, interest_rate numeric)`
	- Decimal and Numeric are same.
	- Numeric can handle any number, even bigger than `bigint`
	- `select 234324234234234234234234324234234::bigint` â† casting // this will throw error as this is large number
	- but same thing will work with numeric.
	- `select 234324234234234234234234324234234::numeric`
	- `select 12::numeric(precision, scale)`
		- 12:345: here precision is 5
		- here scale is 3.
		- if we provide precision and scale extra, then it will cause issues like:
			- select 123.456::numeric(5,3)
	- numeric without parameters will retain everything
	- But numeric with parameter will constraint the value to use or truncate the provided values.
	- `scale` also accept negative values'
- Floating point (done)
	- Integer: Precise very very fast
	-  Numeric: Supports fractions, very very precise, very slow
	- Floating: Supports fractions, inexact (somewhat inaccurate), very very fast
	- `create table real_example (sensor_name text, reading real)`
	- `real` / `float4`: 4 bytes: 1E-37 to 1E+37 and have 6 digits after decimal place
	- `double prevision`: 8 bytes: 1E-307 to 1E+308 15 digits
	- Generate a series
		- `select * from generate_series(1, 20) num;`
- Storing money (do not use it, not recommended)
	```sql
insert into money_example (item_name, price) values
('Laptop', 1999.99),
('Smartphone', 799),
('Pen', .25),
('Headphone', '$199.99'),
('Smartwatch', 249.75),
('Gaming Console', 299.95);
	```
	- It is fine, but after two decimal places, it start rounding up numbers. Which is not right, for something where fractional amount is large. Example: Crypto, US dollar, where fractional amount is huge converted to other currency.
	- It does not have base currency setting, If you do `show lc_monetory`, it will show the current currency setup, but if you change it to something like pound, the currency sign will change, but the actual value will remain same as dollars.
	```sql
	show lc_monetory;
	set lc_monetory = 'env_GB.UTF-8';
	select 1000::money;
	select * from money_example;
	```
	- Best approach:
		- Store everything in Integers with the lowest possible unit (cents)
			- `select (100.78 * 100)::int4 as cents;`
			- `select (100.78)::numeric(10,4) as money;`
		- For support multiple currency, best approach is to store currency next to value
	- Never rely on Money data-type.
- NaNs and infinity
	```sql
select 'NaN'::numeric; -- NaN
select 'NaN'::float4; -- NaN
select 'NaN'::integer -- not supported

select 'Infinity'::numeric; -- NaN
select 'Infinity'::float4; -- NaN
select 'Infinity'::integer; -- not supported, as integer is bounded with min/max.
	```
	- Infinity can be negative
	- alias: `inf`
	- NaN are equal to NaN in Postgres
	- Infinity are equal to Infinity
	- Infinity + Infinity = infinity
	- Infinity - Infinity = NaN
- Casting types
	```sql
select 100::money; -- $100
select cast(100, money); -- $100
select cast(100, int4); -- 100

-- to know the type
select pg_typeof(100:int8), pg_typeof(cast(100 as int4));

select pg_column_size(100::int2); -- 2
select pg_column_size(100::int4); -- 4
select pg_column_size(100::int8); -- 8

-- numeric
select pg_column_size(1000.12313::numeric); -- 8
select pg_column_size(1000313123.12313::numeric); -- 22
select pg_column_size(10002432523523552.12313::numeric); -- 44
	```
	- `pg_typeof` to know the type of data
	- Numeric is a varying size data type, it will allow anything in there and adjust the size accordingly.
- Characters types (done)
	```sql
create table char_example (
	abbr char(5)
);

insert into char_example (abbr)
values
	('a');

- char/character; -- are same

create table char_example (
	abbr character varying(30)
) -- it is saying that the size can vary of the column

create table char_example (
	abbr character varying -- if we do no pass number to varying, then this is same as `text`
) -- it is saying that the size can vary of the column

	```
	- `char`: Do not use fixed width `char` type, it has certain drawbacks
		- If the size of string in small, then it appends extra spaces at the end of string
		- If the size of string i larger, then it will throw an error.
	- `char varying(n)`: it does pad the extra space to string if the string is small then the defined length.
	- `char varying`: if we do not pass number to varying, then it become similar to `text` data type
		- This can hold large number of characters
	- `text`: this can hold large size of the text. and there is something called `TOAST` which Postgres does behind the scenes to make this text datatype faster, if the string is larger.
- Check constraints (done)
	```sql
create table check_example (
	price number CHECK (price > 0) -- 0
	abbr text check (length(abbr) = 5)
)

insert 
into check_example (price, abbr) 
values
	(-1, 'foo'); -- will result in contstraint error as values is -1

-- currently error thrown is not user understandable, to make it more user friendly, we can add custom message on checks

create table check_example (
	price constraint price_must_be_positive check (price > 0),
	abbr text check (length(abbr) = 5)
)

-- currently above constraints are column level constraints, to make them table level constraints, we can define them separately out of column name

create table check_example (
	price numeric check (price > 0),
	discount_price numeric check (discount_price > 0),
	abbr text,
	check (length(abbr) = 5),
	check (price > discount_price) -- this is best practise of define these type of constraints on table level.
)
	```
	- check constraints are good to force data integrity
- Domain types (done)
	```sql
-- postal code in america: 05345-2341
-- postal code can be of 5 digits
create table domain_example (
	street text not null
	city text not null
	postal text
);

-- text is fine, but we can use Domain here
create domain us_postal_code as text constraint format CHECK (
 value ~ '^\d{5}$' or value ~ '^\d{5}-\d{4}$'
);

-- now we can use the above domain, it behave as type
create table domain_example (
	street text not null,
	city text not null,
	postal us_postal_code not null
);

insert into 
	domain_example (street, city, postal)
values
	('main', 'dallas', '74320'); -- OK

insert into 
	domain_example (street, city, postal)
values
	('main', 'dallas', '74320-2131'); -- OK

insert into 
	domain_example (street, city, postal)
values
	('main', 'dallas', '74320-21a1'); -- FAIL 
	```
- Charsets and collations (done)
	```sql
\l -- it will give list of databases
	-- we are looking for collate when checking database, it should most likely be en_US.UTF-8 and that is what we want, as it supports most of the cases.

\l -- this shows database encoding, but we also have a client encoding, this is reference to the client which we are using to connect to database.

show client_encoding; -- UTF8

select 'abc' = 'ABC' collate 'en_US.UTF-8' as results; -- FALSE
-- these are not equal because in UTF the values are case sensitive.

create collation en_us_ci (
	provider = icu, -- icu stands for International Components for Unicode
	locale = 'en-US-u-ks-level1',
	deterministic = false
);

-- now we try equality again
select 'abc' = 'ABC' collate 'en_us_ci' as results; -- TRUE
	```
- Binary types (done)
	```sql
create table bytea_example (
	file_name text,
	data bytea
)

insert into bytea_example
	(file_name, data)
values
	('hello.txt', '\x2423423423423523524234324');

-- to check byte-output type
show bytea_output; -- hex
set bytea_output = 'escape'; -- this will convert byte to normal string and present to you, but not all bytes can be converted to string, something like image, then it will show random numbers. It is recommended to stick with hex.

-- postgres have md5 function as well
select md5('hello world'); -- not secure

select pg_typeof(md5('hello world')); -- text
select pg_typeof(sha256('hello world')); -- bytea

-- to convert md5 to bytea
select pg_typeof(decode(md5('hello world'), 'hex')); -- bytea
select pg_column_size(decode(md5('hello world'), 'hex')); -- 20
select pg_column_size(md5('hello world')); -- 36

-- but if we try the uuid representation
select pg_column_size(md5('hello world') :: uuid); -- 16, uuid is the smallest representation of md5 hash
	```
	- This is not recommended to store large amount of data in database
	- You can Document Storage, something like AWS S3.
	- Binary type does support up-to 1GB of data in the column.
- UUIDs (Done)
	```sql
create table uuid_example (
	uuid_value UUID
);

insert into uuid_example (uuid_value)
values
	('55asdad23adda-sdfsd-234dadd-saaaftrrewqr2332');

select uuid_value, pg_typeof(uuid_value), pg_column_size(uuid_value)
from uuid_example;

select gen_random_uuid();
	```
	- UUID only takes 16 bytes
	- If we convert UUID to Text, then it changes to 40 bytes.
	- If you are storing UUID, store in UUID type.
- Boolean
	```sql
create table boolean_example (
	id serial primary key,
	status boolean
);

insert into boolean_example (status) values
(TRUE), -- TRUE
(FALSE), -- FALSE
('t'), -- TRUE
('true'), -- TRUE
('f'), -- FALSE
('false'), -- FALSE
('1'), -- TRUE
('0'), -- FALSE
('on'), -- TRUE
('off'), -- FALSE
('yes'), -- TRUE
('no'), -- FALSE
(NULL); -- NULL means 'unknown'
	```
	- Boolean size is 1 byte in Postgres
- Enums (done)
	```sql
create type mood as enum ('happy', 'sad'. 'neutal');

create table enum_example (
	current_mood mood -- here we defined mood as data-type
);

insert into enum_example (current_mood) values ('happy'), ('sad'); -- here it will check that whatever value we pass in does match with one of the enum, otherwise it will throw an error.

select * from enum_example order by current_mood; -- here is something different, the ordering will follow the sequence of enum mood defined in (happy, sad, neutral). This will be beneficial when defining size or something like that.

-- but if want to add value to enum
alter type mood add value 'excited'; -- this will add the value at the end of the enum list, and that can affect the ordering if there is any ordering if we are doing on the base of enum.

-- to insert new enum at particular index, we can do the following
alter type mood add value 'afraid' before 'sad';
alter type mood add value 'melancholic' after 'afraid';


create type mood as enum ('happy', 'sad', 'neutral', 'afraid');

begin;
update enum_example set current_mood = 'neutral'
where current_mood not in ('happy', 'sad', 'neutral', 'afraid');

alter table enum_example
alter column current_mood type mood_new using current_mood::text::mood_new;

commit;

select current_mood::int4 from enum_example;

select * from pg_catalog.pg_enum;
-- this will have following columns
-- oid, enumtypeid, enumsortorder, enumlabel

-- to show how the enums were first inserted into
select enum_range(null::mood); -- this will show all enums
select enum_range(null::mood, 'sad'::mood); -- this will show from beginning to sad
select enum_range('afraid'::mood, 'sad'::mood); -- this will show only from afraid to sad
	```
	- we can use `check constraint` in place of enum, but we are loosing the low 1 byte from enum.
	- Keep in mind the sort order issue.
- Timestamps (done)
	```sql
create table timestamp_example (
	"id" serial primary key
	"timestamp" timestamp -- without timezone
);

create table timestamp_example (
	"id" serial primary key
	"timestamp" timestamptz(0-6) -- with timezone
);

select now()::timestamptz(1), now()::timestamptz(0), now()::timestamptz;
-- the result will have one fraction of a second, 
-- with (0) it will round off the second and may provide next future second.
-- without any value, it will have 3 fraction of seconds.
-- as a practice you can use 3 fraction of seconds.

-- ISO 8601 is the best way to store datetime in database
-- 2024-01-31 11:30:08

show DateStyle; -- "ISO, DMY"
-- before the comma: determines the output
-- after the comma: determines the ambigous date settings, you can pass the datetime in defined format DMY, or something lile MDY.
-- DMY stands for Date, Month, Year

-- if we have DMY, the output of 
select '1/3/2024'::date; -- March 1st, 2024
-- if we have MDY, the output of 
select '1/3/2024'::date; -- January 3rd, 2024

-- it is better to stick with default ISO
	```
- Timezones (done)
	```sql
-- Keep the timezones in UTC as long as possible
-- Convert to user needs at the latest moment when showing to the user

-- Use named timezones, not offsets

-- you can get roast if you use hour offset

show time zone;

set time zone 'America/Chicago';

-- this will set the timezone for the session, but to alter the timezone
-- of the database, you can do following:

alter database demo set time zone 'UTC';

-- or you can modify the config file and that will modify the timezone on cluster level, you have to reload the config file after update. Think before you do that as cluster level will affect all the databases
show config_file;

-- ok, currently we have UTC timezone set
select '2024-01-31 11:30:08+00:00':timestamptz; -- 2024-01-31 11:30:08+00:00
-- this will pick the record from table and convert it to the timestamp set currently

-- to test this if we modify the timezone
set time zone 'America/Chicago';
select '2024-01-31 11:30:08+00:00':timestamptz; -- 2024-01-31 05:30:08-06:00

-- flip the sign problem
select  '2024-01-31 11:30:08'::timestamptz,
		'2024-01-31 11:30:08'::timestamptz at time zone 'America/Chicago'
		'2024-01-31 11:30:08'::timestamptz at time zone 'CST' as cst
		'2024-01-31 11:30:08'::timestamptz at time zone 'CDT' as cdt
		'2024-01-31 11:30:08'::timestamptz at time zone '+06:00' as hour_offset
		'2024-01-31 11:30:08'::timestamptz at time zone interval '-06:00' as interval_offset;
-- 2024-01-31 11:30:08+00 | 2024-01-31 05:30:08 | 2024-01-31 05:30:08 | 2024-01-31 06:30:08 | 2024-01-31 17:30:08 | 2024-01-31 05:30:08 

-- To get the list of timezone from postgres
select *
from
	pg_timezone_names;
-- this will give: name | abbrev | utc_offset | is_dst
-- dst stands for: daylight saving time.
-- is_dst taken under consideration, when we use names timezone.
	```
	- Caveat: Use Named timezone
		- It will save from day-light saving time
		- It will not cause problem, if accidentally we flip the sign
- Dates and times (done)
	```sql
-- this is for when user store date and time separately
create table date_time_examples (
	date_col date
);

select '1/3/2024'::date;

show DateStyle; -- ISO, MDY

-- when using date and time, it is not recommened to store them seperatly in different columns.

create table date_time_examples (
	time_col time
);

create table date_time_examples (
	time_col time with time zone -- it is not recommended, as this is outside of date.
);

select 'allballs'::time; -- 00:00:00
select 'epoch'::timestamp; -- 1970-01-01 00:00:00
select 'epoch'::time; -- throw error, because it is not time, it is timestamp with date
select 'tomorrow'::timestamp;

select CURRENT_DATE - 1;
select CURRENT_DATE + 1;

-- dont user with current time
select CURRENT_TIME; -- use timestamp instead
select CURRENT_TIMESTAMP; -- can use this
select LOCALTIME; -- it will give time without any timezone

-- avoid using just time with timezone
	```
- useful commands
```sql
\d table_name -- describe table
\x auto -- preetify data according to screensize
\l -- list databses
```