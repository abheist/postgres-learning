- Introduction to Indexes
```sql
-- Best way to unlock a performant database

-- Indexes are separate datastructure from table
-- most common form of data structure is b-tree
-- it maintains a copy/part of our data
-- Suppose, if we put a index on last name, then it will take all the last names and put them in index in such a way that it will be easy for us to traverse the index to quickly look somebody by last name.
-- Don't create database for everything, that will slow our database down
-- Each index contains a pointer back to the table to provide the full row
-- In most of the database, each index is pointing to the primary key of the row, but in postgres, it is pointer, not the primary key.
```
- Heaps and CTIDs
```sql
-- Under the hood postgres has bunch of pages, bunch of equal size blocks
-- under each page, we have equal chunks of data, then we have positions where the rows are. Support we have page 0, row 10. then that is discrete identifier, and this identifier gets used in indexes.
-- This mechanism by which these rows are written, this structure is just a heap.

select * from reservations;
-- when we do this, we think that all the columns are visible, but that is not the case. there are few system columns which are always hidden. like:
select *, ctid from reservations;
-- these ctids can and will change, so don't put app logic with them in actual query.
-- postgres vacuum change all the rows and ctid get changes as per space on the heap pages.

-- So, every index contain this CTID (what we were calling pointer), from that it know where exactly is full row.
```
- B-Tree overview
```sql
-- Most of the types indexes uses b-tree structure to store, as b-tree is fast, performant and easy.
-- Once we have the exact index, from there it already have CTID, which have row's full data.
```
- Primary key vs. secondary indexes
```sql
-- In Postgres, every index is actually a secondary index.
-- If we take an example of MySQL, if we declare a primary key, we are simultaneosly declaring a clustered-index, that happens in the background automatically. and in MySQL, clustered-index is the way the data is arranged on the disk. In MySQL, everything is an Index, including table itself, it is b-tree index, where the entire row is held down on the leaf-node. and in MySQL, every-other index is secondary index, which is not clustered-index.
-- In postgres, as we talked, everything is stored on heap, that means, there is no clustered-index in Postgres. Therefore, every index is a secondary index (in terms of MySQL Developer, but in actual it the only index)
-- In postgres, we need to traverse the index tree, and go to the heap.
-- So what is primary key: 
-- - primary key enforces uniqueness
-- - it enforces not null
-- - and automatically creates underlying index for you.
-- - and, when we declare table, we can only declare one primary key

-- but we can have as many indexes in the table.
```
- Primary key types
```sql
-- there are two ways, we can define primary key
-- - Integers
-- - UUIDs
-- 98% of times, favor integer (bigint) types, if you do not have any app-specific need
-- For primary key, we do not want to run out of space at some point of time if the app grows. Recently happened to base camp and was the cause of sudden outage.
-- UUIDs are great, but important for us to know, at this time, there are 7 variants of UUID, and then there are cousins of the UUID. The discussion hinders upon which version of the UUID should we use?
-- and UUIDs are not perfect for index (b-tree) which auto-increment ints, they fit perfectly on b-tree and they remain perfectly balance tree. This is not much of a problem on postgres, but in MySQL, this is a big problem where table is actually is arranged by primary key.
-- There are two drawbacks to using UUID.
-- - size is larger, but using postgres UUID type, we can get that down to 16 bytes, that is lot more compact.
-- - Random insertion is real problem, we can get around this by using UUIDv7 which is time ordered UUID.
-- - but there is pros of UUID as well, we can generate these IDs without coordination or without connecting to Database. This comes in handly when we have multiple clients and need something like optimistic UI. So we create an entity on the client and we can send the ID to DB.
-- - there are people talk about using INT for primary key, that there is security risk, security risk of incrementing attack. To come out of this, there Authentication and Authorization in the system + You should have public id along side with primary key.
```
- Where to add indexes
```sql
-- Indexing is more art then science, building great schema, pretty scientific, building indexes, a little bit more of an art. because you cannot look at your schema and derive good indexes out of them. You must look at your access patterns, how you are quierying the tables, how you are querying the data, that is what derived your indexes. 
-- Now, you may be thinking, indexes are good, I may be adding indexes on every column. That is not a great idea. Remember, Index is a separate data structure which stores a copy of part of your data. So if you have index on every column, then you duplicated your data and not only your inserts, updates and deletes going to be slower because all those different indexes needs to be maintained, even your selects are not going to be performant because in likelyhood, it is better to have one composite index over multiple columns instead of having multiple single indexes over single columns.
-- Rule of thumb: anything which shows up after the "where" clause. You should have an index on that. That is closer, but as a profressional, we should have little bit more depth. So following are also important.
-- - order, group, join and even select is also very important when defining the index strategy.


-- so we have following table:
select * from user limit 10;
-- id, first_name, last_name, email, birthday, is_pro, deleted_at, created_at, updated_at
select count(*) from users;
-- 989908

select * from users where birthday = '1989-02-14';
-- and if we do explain over it:
explain select * from users where birthday = '1989-02-14';
-- you will see, it will be scanning a whole table and that is what we do not want to see.

-- to create an index on birthday
create index bday on users using btree(birthday);
-- now when we do explain, you will see that it is scanning on bday index
-- and this will work with <, between, group, etc
```
- Index selectivity
```sql
-- When it comes to indexing, we also needs to look at column, that is it a good candidate for indexing. is it about how you need to look at your data, and find out is it a good candidate for indexing. Suppose take an example of first_name, and all of them are Abhishek, and if we query, whose names are Abhishek, will index helped here, it didn't narrowed down anything at all.
-- When it comes to indexing, we need to focus on two terms
-- - Cardinality: Number of discrete, distinct values in a column
-- - Selectivity: is a ratio on cardinality.
-- lets take an example of boolean column, the cardinality here is 2, as there are two distinct values. and there are million rows, then this will not going to help us.

select count(distinct birthday) from users;
-- 10950

select 
	(count(distinct birthday)::decimal) / count(*)::decimal)::decimal(7,4)
from users;
-- 0.0111

-- Now, lets do this on primary key ID
select 
	(count(distinct id)::decimal) / count(*)::decimal)::decimal(7,4)
from users;
-- 1.0000, this is perfect selectivity
-- and if we talk about worst selectivity, it could be something like: 0.00000241231, something like is_pro in our table, which is 98% times false.

-- But if we want to put a filter on is_pro, it can be better sometimes, we want only the users who are pros. But we need to check overall benefits of indexing on column.

-- Sometimes, even there is an index, postgres wont go to indexes for querying, suppose in below example:
select count(*) from users where birthday > '1989-02-14'; -- 572K
select count(*) from users where birthday < '1989-02-14'; -- 417K
-- Here if you see the first query, it has almost more than half of the results of table, in that case, it will skip the index and go directly to the table as index won't help in this case.
-- Postgres is not running these queries real time to check that indexes are good candidate for this query, it keeps statistics under the hood and it refers to those, and these statistics can be updated via running ANALYZE on table to by auto-vacuum.
-- 
```
- Composite indexes
```sql
-- indexes over many columns at the same time, instead of creating three discret indexes across three columns, we can create 1 index across all 3 columns.
-- But postgres does have ability to scan two separate indexes and combine their results in intelligent way.

-- But we still get better results with composite indexes.
-- Rule: left most prefix: left-to-right, no-skipping, and stops-at-first-range.

create index multi on users using btree(first_name, last_name, birthday);

select * from users where last_name = 'Singh'; -- took ~6 seconds
-- and if you do explain on above query, you wont see the above created index is getting used.
-- it is happening because, we declare our index as
-- first_name, last_name, birthday
-- whenever we declare a composite index, order matters so so much!!!
-- But when we are writting queries, the order of condition does not matter,
-- But the order of declaring our index does matter, Technical name of this rule is: Left-Most-Prefix.

-- But if you do
select * from users where first_name = 'Abhishek'; -- took micro-seconds
-- and if you do explain, you'll see it is using index.

-- and if you do:
select * from users where first_name = 'Abhishek' and last_name = 'Singh';
-- took micro-seconds
-- Here Left-most-prefix is playing a role.

-- okay, under the hood, it is nested b-tree kinda thing. First it search for first index under composite, which is first_name, then it goes to search for nested composite index, which is last_name and then to birthday.
-- In case of postgres, they did some optimization where we can skip the middle index and even search for last one, that will work. But still we need the starting index to work with, that is why our first query starting with last_name did not worked but when we added first name, it worked.
```
- Composite range
```sql
-- lets create two index

create index first_last_birth on users using btree(
	first_name,
	last_name,
	birthday
);

create index first_last_birth on users using btree(
	first_name,
	birthday,
	last_name
);

-- now if we do select
select * from users where 
	first_name = 'Abhishek'
	and
	last_name = 'Singh'
	and
	birthday < '1989-12-31';
-- here if you do explain, you'll see that it is using first index not the second one, and it is happening because of using the btree most effective way.
-- keep the ranges after the equalities and most probably at the end.
```
- Combining multiple indexes
```sql
-- if we have two indexes on two separate columns, then postgres will query on both and then operate AND or OR on the result.
-- But if we already have a composite index on two columns, postgres will go ahead and use the composite index in case of AND. and will go to descrete indexes in case of OR.

-- You can inspect the queries with explain
-- see different strategies and check which ones works better for you.
```
- Covering indexes
```sql
-- shorthand for creating index
create index "first" on users(first_name); -- OK

-- There is concept of Covering Index, where the DB does not go back to heap to pick the extra data needed in select query. as data is already present in index.

select first_name from users where first_name = 'Abhishek';
-- here if you do the explain, you'll see that query is not going to heap

select first_name, last_name from users where first_name = 'Abhishek';
-- After adding last_name in select, you'll see in explain that query is going to heap as last_name is not part of index.

-- But what is we drop index and create composite again for first_name and last_name
drop index "first";

create index "first" on users(first_name, last_name); -- OK
select first_name, last_name from users where first_name = 'Abhishek';
-- now again, it is not going to heap to pick the data

-- We can also add a piece of data along side of index, but dont even use it for indexing. Kinda little side-car

drop index 'first';

create index 'multi' on users(first_name, last_name) include (id);
-- So what it does, it does not include this ID data as part of btree structure but it shoves it down to leaf node, and have data set there.
-- drawback of this. There is not such, but at most of the times, we need most of the rows, and it is not good practice to shove everything in include. and specially don't shove large columns, like text, JSON or XML, that will blow-up the btree.
```
- Partial indexes
```sql
-- This allows to put an index on portion of a table, include unique constraint
-- something, like, lets put a index on email and only for pro users.

create index email on email users(email) where is_pro is true;

select * from users where email = 'abhishek@gmail.com';

explain select * from users where email = 'abhishek@gmail.com';
-- this query is not going to index yet
-- to tell postges that this needs to be fetched from index, we need to add
explain select * from users where 
	email = 'abhishek@gmail.com'
	and
	is_pro is true;
-- now this query is going to indexes

-- unique index won't allow duplicate entries on index you can add two same emails in unique index, it will throw an error. In cases like this you can use some other condition like
create unique index email on users(email) where deleted_at is null;
-- here as per business logic, there will always be one active email, there can never be 2. so this will allow the unique index.
```
- Index ordering
```sql
-- we can create an index in decending or ascending order

-- when we create index on one columns, postgres will scan the index from front or back, based on the order by clause in the query. So it does not matter even if we create an index in whichever order.

-- But when we are creating composite index, support with two columns, and if we order then both in ascending then that is fine

create index birthday_created_at on users(birthday, created_at);

explain select * from users order by birthday, created_at limit 10;

explain select * from users order by birthday desc, created_at desc limit 10;

-- on both the above cases, indexes will work find and postgres will handle the backward scan of index.

-- the problem comes, when we switch one ordering but not the other.

explain select * from users order by birthday desc, created_at asc limit 10;
-- you'll see the incremental sort now.
-- to fix this: but do this if your query use this ordering
create index birthday_created_at on users(birthday asc, created_at desc);
```
- Ordering nulls in indexes
```sql
-- by default NULLS are treated as larger then any other value but we can that both in query and index construction

select * from users
	order by birthday desc
	limit 10;
-- this will show the null values at the top as NULL is the larger then other values
-- to change that behaviour, we can do
select * from users
	order by birthday desc nulls last -- we can also use "first"
	limit 10;

create index birthday_null_first on users(birthday ASC NULLS FIRST);
```